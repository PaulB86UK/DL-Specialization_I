{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Padding",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jbOm3RuE2kI"
      },
      "source": [
        "#Padding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTj-IXJG1QZU"
      },
      "source": [
        "When submitting encoded sentences to neural network all of then must have the same length, same as with images. So, similar lengths in the sentences is a requirement. There are also APIs to perform padding with the sentences. \n",
        "In this notebook the **pad_sequences** from keras.preprocessing is chosen.\n",
        "```\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "```\n",
        "\n",
        "* **maxlen**: Optional Int, maximum length of all sequences. If not provided, sequences will be padded to the length of the longest individual sequence.\n",
        "* **dtype**: dtype\t(Optional, defaults to int32). Type of the output sequences. To pad sequences with variable length strings, you can use object.\n",
        "* **padding**: String, 'pre' or 'post' (optional, defaults to 'pre'): pad either before or after each sequence.\n",
        "* **truncating** String, 'pre' or 'post' (optional, defaults to 'pre'): remove values from sequences larger than maxlen, either at the beginning or at the end of the sequences.\n",
        "* **value** Float or String, padding value. (Optional, defaults to 0.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqYIRDbIFJL1"
      },
      "source": [
        "tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    sequences, maxlen=None, dtype='int32', padding='pre',\n",
        "    truncating='pre', value=0.0\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sBtxJ5MFJo0"
      },
      "source": [
        "In the following example the list of sentences has been padded out into a matrix and that each row in the matrix has the same length. \n",
        "It achieved this by putting the appropriate number of zeros before the sentence.  So in the case of the sentence 5.3.2.4, it didn't actually do any. In the case of the longer sentence here it didn't need to do any. \n",
        "The padding can be either way before or after the sentence.\n",
        "\n",
        "**Example 2:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMTgHkGQ8u7g",
        "outputId": "66c80dd8-ebb7-4772-fa94-c8d585985b49"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#define the list with the sentences\n",
        "sentences = [\n",
        "    'I love my dog',\n",
        "    'I love my cat',\n",
        "    'You love my dog!',\n",
        "    'Do you think my dog is amazing?'\n",
        "]\n",
        "#Generate an instance of the tokenizer with 100 words, and OOV\n",
        "tokenizer = Tokenizer(num_words = 100, oov_token=\"<OOV>\")\n",
        "#Encode the words in the list of sentences\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "#Generate the dictionary with the encoded values for each word.\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "#Generate arrays with encoded values from the sentences\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "#Add padding (length 5) on the arrays generated\n",
        "padded = pad_sequences(sequences, maxlen=5)\n",
        "print(\"\\nWord Index = \" , word_index)\n",
        "print(\"\\nSequences = \" , sequences)\n",
        "print(\"\\nPadded Sequences:\")\n",
        "print(padded)\n",
        "\n",
        "\n",
        "# Test with words that the tokenizer wasn't fit to and add padding but this time\n",
        "#with length 10.\n",
        "\n",
        "test_data = [\n",
        "    'i really love my dog',\n",
        "    'my dog loves my manatee'\n",
        "]\n",
        "\n",
        "test_seq = tokenizer.texts_to_sequences(test_data)\n",
        "print(\"\\nTest Sequence = \", test_seq)\n",
        "\n",
        "padded = pad_sequences(test_seq, maxlen=10)\n",
        "print(\"\\nPadded Test Sequence: \")\n",
        "print(padded)\n",
        "\n",
        "padded_after = pad_sequences(test_seq, maxlen=9, padding= 'post')\n",
        "print(\"\\nPadded Test Sequence After\")\n",
        "print(padded_after)\n",
        "\n",
        "padded_truncated = pad_sequences(test_seq, maxlen=4, truncating='pre')\n",
        "print(\"\\nPadded Test Sequence Truncated before\")\n",
        "print(padded_truncated)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Word Index =  {'<OOV>': 1, 'my': 2, 'love': 3, 'dog': 4, 'i': 5, 'you': 6, 'cat': 7, 'do': 8, 'think': 9, 'is': 10, 'amazing': 11}\n",
            "\n",
            "Sequences =  [[5, 3, 2, 4], [5, 3, 2, 7], [6, 3, 2, 4], [8, 6, 9, 2, 4, 10, 11]]\n",
            "\n",
            "Padded Sequences:\n",
            "[[ 0  5  3  2  4]\n",
            " [ 0  5  3  2  7]\n",
            " [ 0  6  3  2  4]\n",
            " [ 9  2  4 10 11]]\n",
            "\n",
            "Test Sequence =  [[5, 1, 3, 2, 4], [2, 4, 1, 2, 1]]\n",
            "\n",
            "Padded Test Sequence: \n",
            "[[0 0 0 0 0 5 1 3 2 4]\n",
            " [0 0 0 0 0 2 4 1 2 1]]\n",
            "\n",
            "Padded Test Sequence After\n",
            "[[5 1 3 2 4 0 0 0 0]\n",
            " [2 4 1 2 1 0 0 0 0]]\n",
            "\n",
            "Padded Test Sequence Truncated before\n",
            "[[1 3 2 4]\n",
            " [4 1 2 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
